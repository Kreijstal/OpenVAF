/*
 * ******************************************************************************************
 * Copyright (c) 2019 Pascal Kuthe. This file is part of the VARF project.
 * It is subject to the license terms in the LICENSE file found in the top-level directory
 *  of this distribution and at  https://gitlab.com/jamescoding/VARF/blob/master/LICENSE.
 *  No part of VARF, including this file, may be copied, modified, propagated, or
 *  distributed except according to the terms contained in the LICENSE file.
 * *****************************************************************************************
 */

use logos::{Logos, Source, Slice};
use crate::parsing::Span;
use intrusive_collections::__core::ops::{Range, Deref, DerefMut};
use nom::Slice as NomSlice;
use crate::parsing::lexer::Token::{Unexpected};
use std::io::Read;

//in terms of api this just serves as a lexer token enum. however it actually is the real lexer generated by logos. The struct just does some extra handling that logos doesnt allow (easily)
#[derive(Logos,Debug,PartialEq,Clone,Copy)]
pub enum Token {
    //Newline handling
    #[regex=r"\\\n"]
    MacroDefNewLine,
    #[regex=r"\n"]
    Newline,


    //Actual Tokens


    //required rules
    #[end]
    EOF,
    #[regex = "//[^\n]*"]
    #[token = "/*"]
    #[callback = "ignore_comments"]
    #[error]
    Unexpected,
    UnexpectedEOF,

    //Compiler directives
    #[token="`include"]
    Include,
    #[token="`ifdef"]
    MacroIf,
    #[token="`ifndef"]
    MacroIfn,
    #[token="`elsif"]
    MacroElsif,
    #[token="`else"]
    MacroElse,
    #[token="`define"]
    MacroDef,
    #[token=r"`([:alpha:]|_)([:word:]|\$)*"]
    MacroReference,



    //Identifiers
    #[regex=r"[[:alpha:]_][[:word:]\$]*"]
    SimpleIdentifier,
    #[regex=r"\\[[:print:]&&\S]+\s"]
    EscapedIdentifier,

    //Constants
    #[regex=r#""([^\n"\\]|\\[\\tn"])*""#]
    LiteralString,
    #[regex=r"[0-9][0-9_]*"]
    LiteralUnsignedNumber,
    #[regex=r"[0-9][0-9_]*\.[0-9][0-9_]*[TGMKkmupfa]"]
    #[regex=r"[0-9][0-9_]*\.[0-9][0-9_]*[eE][+-]?[0-9][0-9_]*"]
    #[regex=r"[0-9][0-9_]*[TGMKkmupfa]"]
    #[regex=r"[0-9][0-9_]*[eE][+-]?[0-9][0-9_]*"]
    #[regex=r"[0-9][0-9_]*\.[0-9][0-9_]*"]
    LiteralRealNumber,

    //Symbols
    #[token="."]
    Accessor,
    #[token = ";"]
    Semicolon,
    #[token = ":"]
    Colon,
    #[token = ","]
    Comma,
    #[token = "("]
    ParenOpen,
    #[token = ")"]
    ParenClose,
    #[token="<+"]
    Contribute,
    #[token="="]
    Assign,

    //Arithmatic Operators
    #[token = "*"]
    OpMul,
    #[token = "/"]
    OpDiv,
    #[token = "%"]
    OpRemain,
    #[token="+"]
    Plus,
    #[token="-"]
    Minus,
    #[token = "**"]
    OpExp,
    //UnaryOperators
    #[token = "!"]
    OpLogicNot,
    #[token = "~"]
    OpBitNot,


    #[token = "<<"]
    OpArithmeticShiftLeft,
    #[token = ">>"]
    OpArithmeticShiftRight,

    //Relational
    #[token = "<"]
    OpLT,
    #[token = "<="]
    OpLessEqual,
    #[token = ">"]
    OpGreater,
    #[token = ">="]
    OpGreaterEqual,
    #[token = "=="]
    OpeEqual,
    #[token = "!="]
    OpNotEqual,
    //Logic
    #[token = "&&"]
    OpLogicAnd,
    #[token = "||"]
    OpLogicalOr,

    //Bit
    #[token = "&"]
    OpBitAnd,
    #[token = "^"]
    OpBitXor,
    #[token = "|"]
    OpBitOr,

    //Other
    #[token = "?"]
    OpCondition,
    #[token = "?"]
    OpElse,


    //Keywords
    #[token="if"]
    If,
    #[token="else"]
    Else,

    #[token="begin"]
    Begin,
    #[token="End"]
    End,
    #[token="module"]
    Module,
    #[token="endmodule"]
    EndModule,
    #[token="branch"]
    Branch,
    #[token="parameter"]
    Parameter,
    #[token="localparam"]
    DefineParameter,
    #[token="defparam"]
    LocalParameter,
    #[token="analog"]
    Analog,
    #[token="initial"]
    AnalogInitial,
    #[token="input"]
    Input,
    #[token="inout"]
    Inout,
    #[token="output"]
    Output,

    #[token="signed"]
    Signed,
    #[token="vectored"]
    Vectored,
    #[token="scalared"]
    Scalared,

    #[token="string"]
    String,
    #[token="time"]
    Time,
    #[token="realtime"]
    Realtime,
    #[token="integer"]
    Integer,
    #[token="real"]
    Real,

    #[token="reg"]
    Reg,
    #[token="wreal"]
    Wreal,

    #[token="potential"]
    Potential,
    #[token="flow"]
    Flow,

    #[token="ddt"]
    TimeDerivative,
    #[token="ddx"]
    PartialDerivative,
    #[token="idt"]
    TimeIntegral,
    #[token="idtmod"]
    TimeIntegralMod,
    #[token="exp"]
    Exp,
    #[token="sqrt"]
    Sqrt,
    #[token="pow"]
    Pow,
    #[token="white_noise"]
    WhiteNoise,
    #[token="flicker_noise"]
    FlickerNoise,
    #[token="abs"]
    Abs,
    #[token="from"]
    From,
    #[token="exclude"]
    Exclude,
    #[token="inf"]
    Infinity,

    #[token="nature"]
    Nature,
    #[token="endnature"]
    EndNature,
    #[token="abstol"]
    Abstol,
    #[token="access"]
    Access,
    #[token="ddt_nature"]
    TimeDerivativeNature,
    #[token="idt_nature"]
    TimeIntegralNature,
    #[token="units"]
    Units,
}
fn ignore_comments<'source, Src: Source<'source>>(lex: &mut logos::Lexer<Token, Src>) {//handel comment here since we dont want the resulting token anyway (if i don't do this lexer generation slows to a crawl)
    use logos::internal::LexerInternal;

    if lex.slice().as_bytes() == b"/*" {
        loop {
            match lex.read() {
                0    => return lex.token = Token::UnexpectedEOF,
                b'*' => {
                    if lex.next() == b'/' {
                        lex.bump(1);
                        break;
                    }
                },
                _ => lex.bump(1),
            }
        }
    }
    lex.advance();
}




pub struct Lexer<'lt>{
    internal:logos::Lexer<Token,&'lt str>,
    global_span:Span<'lt>
}
impl<'lt> Lexer<'lt>{
    pub fn new(source:&'lt str)->Self{
        let mut res =Self{
            internal:Token::lexer(source),
            global_span:Span::new(source)
        };
        res.skip();
        res.change_to_error();
        res
    }
    pub fn advance(&mut self){
        self.internal.advance();
        self.skip();
        self.change_to_error();
    }
        fn skip(&mut self){
            while let Token::Newline =  self.internal.token {
                self.internal.advance()
            }
        }
        fn change_to_error(&mut self){
            if let Token::MacroDefNewLine = self.internal.token{
                self.internal.token = Token::Unexpected
            }
        }
    /// Advance inside a macro definition. Here all newlines are preceded by a backslash (\\n) and a normal newline terminates the definition. This method advances the parser like normal but ignores
    pub fn advance_inside_macro_body(&mut self) ->bool{
        self.internal.advance();
        loop{
            match self.internal.token{
                Token::MacroDefNewLine => self.internal.advance(),
                Token::Newline => {
                    self.internal.advance();
                    return false
                },
                _ => return true,
            }
        }
    }
    #[inline]
    pub fn token(&self)->Token{
        self.internal.token
    }
    pub fn span(&self)->Span<'lt>{
        self.global_span.slice(self.internal.range())
    }
    pub fn slice(&self)->&str{
        self.internal.slice()
    }

}







#[cfg(test)]
mod test{
    use super::*;

    #[test]
    pub fn macro_if(){
        let mut lexer = Lexer::new("`ifdef");
        assert_eq!(lexer.token(),Token::MacroIf)
    }
    #[test]
    pub fn macro_ifn(){
        let mut lexer = Lexer::new("`ifndef");
        assert_eq!(lexer.token(),Token::MacroIfn)
    }
    #[test]
    pub fn macro_else(){
        let mut lexer = Lexer::new("`else");
        assert_eq!(lexer.token(),Token::MacroElse)
    }
    #[test]
    pub fn macro_elsif(){
        let mut lexer = Lexer::new("`elsif");
        assert_eq!(lexer.token(),Token::MacroElsif)
    }
    #[test]
    pub fn macro_definition(){
        let mut lexer = Lexer::new("`define");
        assert_eq!(lexer.token(),Token::MacroDef)
    }
    #[test]
    pub fn macro_def_newline(){
        let mut lexer = Lexer::new(r"if\
        test2
        test");
               assert_eq!(lexer.advance_inside_macro_body(), true);
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.advance_inside_macro_body(), false);
        assert_eq!(lexer.token(),Token::SimpleIdentifier)
    }
    #[test]
    pub fn include(){
      assert_eq!(Lexer::new("`include").token(),Token::Include)
    }
    #[test]
    pub fn simple_ident(){
        let mut lexer = Lexer::new("test _test  test2  test$\ntest2_$ iftest");
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.slice(),"test");
        lexer.advance();
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.slice(),"_test");
        lexer.advance();
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.slice(),"test2");
        lexer.advance();
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.slice(),"test$");
        lexer.advance();
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.slice(),"test2_$");
        lexer.advance();
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.slice(),"iftest");
    }
    #[test]
    pub fn escaped_ident(){
        let mut lexer = Lexer::new("\\lel\\\\lel \\if ");
        assert_eq!(lexer.token(),Token::EscapedIdentifier);
        assert_eq!(&lexer.slice()[1..9],"lel\\\\lel");
        lexer.advance();
        assert_eq!(lexer.token(),Token::EscapedIdentifier);
        assert_eq!(&lexer.slice()[1..3],"if");
    }
    #[test]
    pub fn comment(){
        let mut lexer = Lexer::new("//jdfjdfjw4$%\r%&/**#.,|\n/*3\n\r\n_/*_*/ test");
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.slice(),"test")
    }
    #[test]
    pub fn test_span(){
        let mut lexer = Lexer::new("//hallo\n test");
        assert_eq!(lexer.token(),Token::SimpleIdentifier);
        assert_eq!(lexer.slice(),"test");
        assert_eq!(lexer.span().line,2);
        assert_eq!(lexer.span().line,2);
        assert_eq!(lexer.span().offset,9);
    }
    #[test]
    pub fn string(){
        let mut lexer = Lexer::new(r#""lel\"dsd%§.,-032391\t    ""#);
        assert_eq!(lexer.token(),Token::LiteralString);
    }
    #[test]
    pub fn unsigned_number(){
        let mut lexer = Lexer::new("1_2345_5678_9");
        assert_eq!(lexer.token(),Token::LiteralUnsignedNumber);
    }
    #[test]
    pub fn real_number(){
        let mut lexer = Lexer::new("1.2
        0.1
2394.26331
1.2E12 // the exponent symbol can be e or E
1.30e-2
0.1e-0
236.123_763_e-12 // underscores are ignored
1.3u
23E10
29E-2
7k");
        while lexer.token()!=Token::EOF{
            assert_eq!(lexer.token(),Token::LiteralRealNumber);
            lexer.advance()
        }
    }
}